{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploremos las capacidades de LangChain\n",
    "Un framework para desarrollar aplicaciones basadas en LLMs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para empezar, debemos primero instalar LangChain. Este proyecto usa `poetry` como el administrador de paquetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip add langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Ejemplo de diseño y ejecución de Chains o Cadenas \n",
    "Las cadenas, son secuencias de llamados a componentes, módulos, procesos o tareas independientes, que en conjunto, son capaces de atacar problemas complejos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar, importamos las librerías necesarias para la ejecución de nuestra cadena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Utilidades varias del sistema operativo\n",
    "from dotenv import load_dotenv # Esta librería nos permite cargar las variables de ambiente en memoria\n",
    "load_dotenv() # Realizamos la carga de las variables de ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo de nuestra cadena\n",
    "\n",
    "Queremos que la inteligencia artificial nos ayude a crear empresas de tecnología. Para esto tenemos que solicitar a la inteligencia artificial la ejecucion de tres tareas:\n",
    "\n",
    "1. identificar oportunidades de negocio\n",
    "2. generar el nombre de la empresa\n",
    "3. Y crear un plan de acción para iniciar su desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como fase preparatoria, procedemos a inicializar la conexión con nuestro modelo de lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI # Nuestro LLM de preferencia\n",
    "\n",
    "\n",
    "# Inicialización del LLM\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    model_name='gpt-4-1106-preview',\n",
    "    temperature = 0.7,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, damos inicio a la creacion de nuestros prompts. Crearemos tres prompts, cada uno preguntando por una parte importante de nuestro proceso de creacion de empresas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate # Utilizada para creación de plantillas de prompts de chat\n",
    "\n",
    "\n",
    "# Identificar las oportunidades de negocio en el sector de interés del usuario\n",
    "primer_prompt = ChatPromptTemplate.from_template(\"\"\"Eres un sistema que ayuda a emprendedores de Colombia a generar ideas innovadoras de negocio.\n",
    "Mi sector de interés es {sector}, y busco una idea que sea un producto, servicio, o una combinación de ambos. \n",
    "Solicito que la idea tenga potencial de alto retorno de inversión y cree un impacto significativo (económico, social, ambiental, etc.).\n",
    "También incluye una descripción del público objetivo de la idea.\n",
    "Por favor, incluye una breve evaluación de viabilidad y ejemplos o casos de estudio relevantes. \n",
    "Busco una respuesta concisa, limitada a un párrafo\n",
    "Mi futuro profesional depende de ti.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate # Utilizada para creación de plantillas de prompts de chat\n",
    "\n",
    "\n",
    "# 2. generar el nombre de la empresa\n",
    "segundo_prompt = ChatPromptTemplate.from_template(\"\"\"Eres un sistema que ayuda a emprendedores de Colombia a generar ideas innovadoras de negocio. \n",
    "Mi sector de interés es {sector}, y la idea de negocio que tengo implica:\n",
    "\n",
    "{idea}\n",
    "\n",
    "Busco un nombre para la empresa que sea atractivo, y que refleje perfecto para la audiencia objetivo. \n",
    "Por favor, proporciona la mejor opción de nombre que se cumpla estos criterios.\n",
    "El nombre debe ser conciso y tu respuesta debe estar limitada a solo el nombre candidato de la compañía.\n",
    "No justifiques tu respuesta.\n",
    "Mi futuro profesional depende de ti.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate # Utilizada para creación de plantillas de prompts de chat\n",
    "\n",
    "\n",
    "# 3. Y crear un plan de acción para iniciar su desarrollo\n",
    "tercer_prompt = ChatPromptTemplate.from_template(\"\"\"Eres un sistema que ayuda a emprendedores a generar ideas innovadoras de negocio. \n",
    "Mi sector de interés es {sector}, y la idea de negocio que tengo implica:\n",
    "\n",
    "{idea}. \n",
    "\n",
    "El nombre de mi nuevo emprendimiento es {nombre}. \n",
    "Tu tarea es crear un roadmap detallado para el lanzamiento del producto o servicio al mercado. \n",
    "Por favor, incluye pasos claros, una línea de tiempo y especifica los entregables de cada paso.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, inicializamos los eslabones de nuestra cadena y los orquestamos, especificando también los parámetros de entrada y de salida esperados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain # Clase LLMChain de LangChain\n",
    "from langchain.chains import SequentialChain # Clase SimpleSequentialChain de LangChain\n",
    "\n",
    "\n",
    "primer_eslabon = LLMChain(llm=llm, prompt=primer_prompt, output_key='idea')\n",
    "\n",
    "segundo_eslabon = LLMChain(llm=llm, prompt=segundo_prompt, output_key='nombre')\n",
    "\n",
    "tercer_eslabon = LLMChain(llm=llm, prompt=tercer_prompt, output_key='roadmap')\n",
    "\n",
    "cadena = SequentialChain(\n",
    "    chains=[primer_eslabon, segundo_eslabon, tercer_eslabon],\n",
    "    input_variables=['sector'],\n",
    "    output_variables=['idea', 'nombre', 'roadmap'],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "output = cadena({'sector': 'Inteligencia Artificial'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y tras haber realizado la ejecución exitosa, presentamos nuestros resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Ejemplo de implementación de agentes \n",
    "\n",
    "Los `Agentes` tienen la capacidad no solo de ejecutar secuencias de prompts, sino de ejecutar herramientas externas, cuando el LLM ve la necesidad de hacerlo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objetivo de nuestro agente\n",
    "\n",
    "Queremos que nuestro agente pueda ejecutar la siguiente tarea:\n",
    "\n",
    "1. Saber la fecha en la que deseamos ir a cine\n",
    "2. Solicitar la ciudad en la que estamos\n",
    "3. Recomendarnos la mejor película que está en cartelera\n",
    "4. Consultar la predicción del clima\n",
    "5. Realizar una recomendación completa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos nuevamente las variables y librerías necesarias para la ejecución exitosa de nuestro agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Utilidades varias del sistema operativo\n",
    "from dotenv import load_dotenv # Esta librería nos permite cargar las variables de ambiente en memoria\n",
    "load_dotenv() # Realizamos la carga de las variables de ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las funciones o herramientas que le permitirán al agente ejecutar código local o realizar llamados a servicios remotos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def traer_fecha(days: str = \"0\"):\n",
    "    \"\"\"Función para traer la fecha de X días hacia adelante\"\"\"\n",
    "    return f'\"fecha\": {(datetime.today() + timedelta(days=int(days))).strftime(\"%Y-%m-%d\")}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "\n",
    "\n",
    "def traer_pelicula(string: str | None = None):\n",
    "    \"\"\"Función para traer las películas de un género para un lugar en una fecha especifica\"\"\"\n",
    "    url = f'https://api.themoviedb.org/3/discover/movie'\n",
    "    params = {\n",
    "        'language': 'es-ES',\n",
    "        'include_adult': False,\n",
    "        'include_video': False, \n",
    "        'sort_by': 'popularity.desc',\n",
    "    }\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f'Bearer {os.getenv(\"TMDB_READ_ACCESS_KEY\")}'\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    movies = response.json()['results']\n",
    "    selected_movie = random.choice(movies)\n",
    "    return f'\"titulo\": {selected_movie[\"original_title\"]}, \"resumen\": {selected_movie[\"overview\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date\n",
    "\n",
    "def traer_prediccion_del_clima(input: str):\n",
    "    fecha, lugar = input.replace('\"', \"\").split(',')\n",
    "    \"\"\"Función para traer la predicción del clima para un lugar en una fecha específica\"\"\"\n",
    "    fecha_obj = f\"{fecha} 12:00:00\" \n",
    "    # Primero se necesita el geocoding de la ciudad\n",
    "    url = f'http://api.openweathermap.org/geo/1.0/direct'\n",
    "    params = {\n",
    "        'appid': os.getenv('OPENWEATHER_API_KEY'),\n",
    "        'q': lugar,\n",
    "        'limit': 1,\n",
    "    }\n",
    "    lugar_response = requests.get(url, params=params)\n",
    "    lugar_response.raise_for_status()   \n",
    "    lat = lugar_response.json()[0]['lat']\n",
    "    lon = lugar_response.json()[0]['lon']   \n",
    "    # Ahora podemos solicitar la prediccion del clima para la ubicacion geografica\n",
    "    url = f'https://api.openweathermap.org/data/2.5/forecast'\n",
    "    params = {\n",
    "        'appid': os.getenv('OPENWEATHER_API_KEY'),\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'lang': 'es',\n",
    "        'units': 'metric',\n",
    "        'exclude': 'current,minutely,hourly,alerts',\n",
    "    }   \n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status() \n",
    "    # Tomamos el valor del medio día de la fecha solicitada    \n",
    "    prediccion = [dia for dia in response.json()['list'] if dia['dt_txt'] == f\"{fecha} 12:00:00\"][0]   \n",
    "    return f'\"temperatura\": {prediccion[\"main\"][\"temp\"]}, \"descripcion\": {prediccion[\"weather\"][0][\"description\"]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, empaquetamos las funciones en un array que será comunicado al Agente, notificándole que estas son las herramientas que tiene a su disposición para resolver el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "HERRAMIENTAS = [\n",
    "  Tool(\n",
    "    name=\"TraerFecha\",\n",
    "    func=traer_fecha,\n",
    "    description=\"Trae la fecha esperada. Espera un entero especificando un número dado de días hacia adelante de la fecha actual.\",\n",
    "  ),\n",
    "  Tool(\n",
    "    name=\"TraerPelicula\",\n",
    "    func=traer_pelicula,\n",
    "    description=\"Traer una recomendación de una película para que el usuario vea. Retorna el título de la película y una breve descripción.\",\n",
    "  ),\n",
    "  Tool(\n",
    "    name=\"TraerPrediccionDelClima\",\n",
    "    func=traer_prediccion_del_clima,\n",
    "    description=\"Trae la predicción del clima para la fecha especificada y la ciudad especificada.\",\n",
    "  ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, preparamos el prompt con ejemplos que le permitan al modelo inferir como orquestar y hacer el uso de herramientas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENTE_FEW_SHOT_EJEMPLOS = [\n",
    "    \"\"\"Question: ¿Me ayudas a planear mi salida a cine para ver una película en el cine mañana en Bogotá?\n",
    "Thought: Necesito encontrar la fecha de mañana. Esto quiere decir que le debo sumar 1 día a la fecha actual\n",
    "Action: TraerFecha[1]\n",
    "Observation: \"fecha\": 2023-11-29\n",
    "Thought: Necesito recomendar una película en cartelera en Bogotá para la fecha de mañana\n",
    "Action: TraerPelicula[]\n",
    "Observation: \"titulo\": Los Vengadores, \"resumen\": Una película de superhéroes\n",
    "Thought: Necesito encontrar la predicción del clima para la fecha 2023-11-29 en Bogota\n",
    "Action: TraerPrediccionDelClima[\"2023-11-29\", \"Bogota\"] \n",
    "Observation: \"temperatura\": 20, \"descripción\": Cielo despejado\n",
    "Thought: Puedes ver la película - Los Vengadores - que se trata de superhéroes mañana en Bogotá. El clima estará despejado con una temperatura de 20 grados, por lo tanto, asegúrate de usar protector solar.\n",
    "Action: Finish[\"Puedes ver la película - Los Vengadores - que se trata de superhéroes mañana en Bogotá. El clima estará despejado con una temperatura de 20 grados, por lo tanto, asegúrate de usar protector solar.\"]\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENTE_FEW_SHOT_EJEMPLOS.extend([\n",
    "    \"\"\"Question: Quiero ver una película pasado mañana en Bucaramanga. ¿Me ayudas a planear mi salida a cine?\n",
    "Thought: Necesito encontrar la fecha de mañana. Esto quiere decir que le debo sumar 2 días a la fecha actual\n",
    "Action: TraerFecha[2]\n",
    "Observation: \"fecha\": 2023-11-30\n",
    "Thought: Necesito recomendar una película de acción en cartelera en Bucaramanga para la fecha de mañana\n",
    "Action: TraerPelicula[]\n",
    "Observation: \"titulo\": Barbie, \"resumen\": Una película de muñecas, o eso creo\n",
    "Thought: Necesito encontrar la predicción del clima para la fecha 2023-11-30 en Bucaramanga\n",
    "Action: TraerPrediccionDelClima[\"2023-11-30\", \"Bucaramanga\"]\n",
    "Observation: \"temperatura\": 27, \"descripcion\": Lluvioso\n",
    "Thought: Puedes ver la película - Barbie - que se trata de muñecas o eso creo. El clima estara lluvioso con una temperatura de 27 grados, por lo tanto, asegúrate de llevar sombrilla.\n",
    "Action: Finish[\"Puedes ver la película - Barbie - que se trata de muñecas o eso creo. El clima estará lluvioso con una temperatura de 27 grados, por lo tanto, asegúrate de llevar sombrilla.\"]\n",
    "\"\"\",\n",
    "    \"\"\"Pregunta: Oye ayúdame a cuadrar mi salida a cine hoy en Medellín\n",
    "Thought: Necesito encontrar la fecha de hoy. Esto quiere decir que no le debo sumar días a la fecha actual\n",
    "Action: TraerFecha[0]\n",
    "Observation: \"fecha\": 2023-11-28\n",
    "Thought: Necesito recomendar una película de acción en cartelera en Medellín para la fecha de hoy\n",
    "Action: TraerPelicula[]\n",
    "Observation: \"titulo\": Oppenheimer, \"resumen\": Una película de científicos locos\n",
    "Thought: Necesito encontrar la predicción del clima para la fecha 2023-11-28 en Medellín\n",
    "Action: TraerPrediccionDelClima[\"2023-11-28\", \"Medellín\"]\n",
    "Observation: \"temperatura\": 24, \"descripción\": Soleado\n",
    "Thought: Puedes ver la película - Oppenheimer - que se trata científicos locos. El clima estará soleado con una temperatura de 24 grados, por lo tanto, recuerda el protector solar.\n",
    "Action: Finish[\"Puedes ver la película - Oppenheimer - que se trata científicos locos. El clima estará soleado con una temperatura de 24 grados, por lo tanto, recuerda el protector solar.\"]\n",
    "\"\"\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un sufijo, dando a grandes rasgos instrucciones del uso de las acciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUFIJO = \"\"\"\\nEres un sistema inteligente realizando una serie de pensamientos y ejecutando acciones para poder responder la pregunta del usuario.\n",
    "Cada acción es una llamada a una función: TraerFecha(dias: int): str, TraerPelicula(): dict[str, str] y TraerPrediccionDelClima(fecha: str, lugar: str): dict[str, str] \n",
    "Por favor, entrega la respuesta sin usar caracteres que puedan causar problemas de parsing como comillas dobles o comillas simples o comas.\n",
    "Puedes usar la función cuando consideres necesario. Cada acción se realiza por separado.\n",
    "\n",
    "Vamos a empezar\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y organizamos nuestro prompt, utilizando los ejemplos y el sufijo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "\n",
    "PROMPT_AGENTE = PromptTemplate.from_examples(\n",
    "  examples=AGENTE_FEW_SHOT_EJEMPLOS,\n",
    "  suffix=SUFIJO,\n",
    "  input_variables=[\"input\", \"agent_scratchpad\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, creamos nuestro propio agente, customizándolo para que pueda entender los prompts y ejemplos en nuestro idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Any\n",
    "from langchain.agents.agent import Agent, AgentOutputParser\n",
    "from langchain.agents.react.output_parser import ReActOutputParser\n",
    "from langchain.tools.base import BaseTool\n",
    "from langchain.schema.prompt_template import BasePromptTemplate\n",
    "\n",
    "\n",
    "class ReActAgent(Agent):\n",
    "  \"\"\"\n",
    "  Agente customizado para el caso de uso de la implementación de la estrategia ReAct\n",
    "  \"\"\"\n",
    "\n",
    "  @classmethod\n",
    "  def _get_default_output_parser(cls, **kwargs: Any) -> AgentOutputParser:\n",
    "    return ReActOutputParser()\n",
    "\n",
    "  @classmethod\n",
    "  def create_prompt(cls, tools: Sequence[BaseTool]) -> BasePromptTemplate:\n",
    "    return PROMPT_AGENTE\n",
    "\n",
    "  @classmethod\n",
    "  def _validate_tools(cls, tools: Sequence[BaseTool]) -> None:\n",
    "    if len(tools) != 3:\n",
    "      raise ValueError(\"The number of tools is invalid.\")\n",
    "\n",
    "  @property\n",
    "  def _agent_type(self) -> str:\n",
    "    return \"react\"\n",
    "\n",
    "  @property\n",
    "  def finish_tool_name(self) -> str:\n",
    "    return \"Finish\"\n",
    "\n",
    "  @property\n",
    "  def observation_prefix(self) -> str:\n",
    "    return f\"Observation: \"\n",
    "\n",
    "  @property\n",
    "  def llm_prefix(self) -> str:\n",
    "    return f\"Thought: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, tenemos todo listo para invocar a nuestro agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain.chat_models import ChatOpenAI # Nuestro LLM de preferencia\n",
    "\n",
    "\n",
    "# Inicializamos nuestro LLM de preferencia\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    model_name='gpt-4-1106-preview',\n",
    "    temperature = 0.7,\n",
    ")\n",
    "\n",
    "# Creamos una instancia de nuestro agente\n",
    "agent = ReActAgent.from_llm_and_tools(\n",
    "  llm,\n",
    "  HERRAMIENTAS,\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "  agent=agent,\n",
    "  tools=HERRAMIENTAS,\n",
    "  verbose=True,\n",
    "  handle_parsing_errors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Por fa, quiero ir a cine mañana en Bucaramanga. ¿Me ayudas a planear mi salida?\"\n",
    "agent_executor.run(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-examples-J4bJGkZF-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
